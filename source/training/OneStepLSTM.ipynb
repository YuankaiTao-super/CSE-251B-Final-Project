{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb8d9f0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-09T00:22:22.765053Z",
     "iopub.status.busy": "2025-06-09T00:22:22.764375Z",
     "iopub.status.idle": "2025-06-09T00:22:29.171264Z",
     "shell.execute_reply": "2025-06-09T00:22:29.170390Z"
    },
    "papermill": {
     "duration": 6.413192,
     "end_time": "2025-06-09T00:22:29.172541",
     "exception": false,
     "start_time": "2025-06-09T00:22:22.759349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cse-251-b-2025/train.npz\n",
      "/kaggle/input/cse-251-b-2025/test_input.npz\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc0c0c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:22:29.180789Z",
     "iopub.status.busy": "2025-06-09T00:22:29.180447Z",
     "iopub.status.idle": "2025-06-09T00:22:29.190492Z",
     "shell.execute_reply": "2025-06-09T00:22:29.189736Z"
    },
    "papermill": {
     "duration": 0.015164,
     "end_time": "2025-06-09T00:22:29.191657",
     "exception": false,
     "start_time": "2025-06-09T00:22:29.176493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # for single-GPU\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "\n",
    "    # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531f6935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:22:29.199102Z",
     "iopub.status.busy": "2025-06-09T00:22:29.198699Z",
     "iopub.status.idle": "2025-06-09T00:22:45.345023Z",
     "shell.execute_reply": "2025-06-09T00:22:45.344339Z"
    },
    "papermill": {
     "duration": 16.151311,
     "end_time": "2025-06-09T00:22:45.346358",
     "exception": false,
     "start_time": "2025-06-09T00:22:29.195047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "train_file = np.load('/kaggle/input/cse-251-b-2025/train.npz')\n",
    "# train_file = np.load('/kaggle/input/cse-251-b-2025/train.npz')\n",
    "\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('/kaggle/input/cse-251-b-2025/test_input.npz')\n",
    "# test_file = np.load('/kaggle/input/cse-251-b-2025/test_input.npz')\n",
    "\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb58f4",
   "metadata": {
    "papermill": {
     "duration": 0.003251,
     "end_time": "2025-06-09T00:22:45.353187",
     "exception": false,
     "start_time": "2025-06-09T00:22:45.349936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TrajectoryDataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99e5e5a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:22:45.360843Z",
     "iopub.status.busy": "2025-06-09T00:22:45.360600Z",
     "iopub.status.idle": "2025-06-09T00:22:46.521059Z",
     "shell.execute_reply": "2025-06-09T00:22:46.520198Z"
    },
    "papermill": {
     "duration": 1.165721,
     "end_time": "2025-06-09T00:22:46.522208",
     "exception": false,
     "start_time": "2025-06-09T00:22:45.356487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 245])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([60, 2])\n",
      "torch.Size([60, 2])\n",
      "torch.Size([60, 2])\n",
      "torch.Size([60, 1])\n"
     ]
    }
   ],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, data_tensor, isTest) :\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_tensor: Tensor of shape (num_scenes, num_agents, timesteps, features)\n",
    "                         Expected to be (10000, 50, 110, 6)\n",
    "        \"\"\"\n",
    "        self.data = torch.tensor(data_tensor)\n",
    "        self.num_scenes = data_tensor.shape[0]\n",
    "        self.num_agents = data_tensor.shape[1]\n",
    "        self.timesteps = data_tensor.shape[2]\n",
    "        self.isTest = isTest\n",
    "        self.train = False\n",
    "        # Validate input shape\n",
    "        if len(data_tensor.shape) != 4 or data_tensor.shape[3] != 6:\n",
    "            raise ValueError(\"Input tensor must have shape (scenes, agents, timesteps, 6 features)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_scenes\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        scene_tensor = self.data[idx].clone()\n",
    "        \n",
    "        yaw = scene_tensor[0, 0, 4]\n",
    "        rot_mat = torch.tensor([\n",
    "            [torch.cos(-yaw), -torch.sin(-yaw)],\n",
    "            [torch.sin(-yaw),  torch.cos(-yaw)]\n",
    "        ])\n",
    "        \n",
    "        # add slight noise to tolerate noisy\n",
    "        # max_theta_deg = 15\n",
    "        # if np.random.rand() < 0.5:\n",
    "        #     theta = np.radians(np.random.uniform(-max_theta_deg, max_theta_deg))\n",
    "        #     noise_rot = torch.tensor([\n",
    "        #         [math.cos(theta), -math.sin(theta)],\n",
    "        #         [math.sin(theta),  math.cos(theta)]\n",
    "        #     ], dtype=rot_mat.dtype, device=rot_mat.device)\n",
    "        #     rot_mat = noise_rot @ rot_mat \n",
    "            \n",
    "        ego_pos = scene_tensor[0, :, :2]\n",
    "        roted_ego_pos = scene_tensor[0, :, :2] @ rot_mat.T # (110,2)\n",
    "        roted_ego_vel = scene_tensor[0, :, 2:4] @ rot_mat.T # (110,2)\n",
    "        ego_yaw = scene_tensor[0, :, 4] # (110, )\n",
    "        \n",
    "        # rotated ego positions difference features (falttened at last)\n",
    "        roted_ego_pos_diff = roted_ego_pos[1:] - roted_ego_pos[:-1] # (109,2)\n",
    "        if not self.isTest:\n",
    "            roted_ego_pos_diff_init  = roted_ego_pos_diff[:-60]  # (49,2)\n",
    "            roted_ego_pos_diff_target = roted_ego_pos_diff[-60:] #  (60,2)\n",
    "        else:\n",
    "            roted_ego_pos_diff_init = roted_ego_pos_diff\n",
    "        roted_ego_pos_diff_window = roted_ego_pos_diff_init.reshape(1,-1) # (1, 98), row-major order flatten\n",
    "        ### Train data-only data transformations (regularization)\n",
    "        # if not self.isTest and self.train:\n",
    "        #     roted_ego_pos_diff_window += torch.normal(mean=0, std=0.05, size=roted_ego_pos_diff_window.shape)\n",
    "\n",
    "        # rotated ego velocity difference features (falttened at last)\n",
    "        roted_ego_vel_diff = roted_ego_vel[1:] - roted_ego_vel[:-1] # (109,2)\n",
    "        if not self.isTest:\n",
    "            roted_ego_vel_diff_init = roted_ego_vel_diff[:-60] # (49,2)\n",
    "            roted_ego_vel_diff_target = roted_ego_vel_diff[-60:] # (60,2)\n",
    "        else:\n",
    "            roted_ego_vel_diff_init = roted_ego_vel_diff\n",
    "        roted_ego_vel_diff_window = roted_ego_vel_diff_init.reshape(1,-1) # (1, 98), row-major order flatten\n",
    "\n",
    "        # ego yaw angle difference features \n",
    "        ego_yaw_diff = ego_yaw[1:] - ego_yaw[:-1] # (109,)\n",
    "        if not self.isTest:\n",
    "            ego_yaw_diff_init = ego_yaw_diff[:-60]  # (49,)\n",
    "            ego_yaw_diff_target = ego_yaw_diff[-60:] # (60,)\n",
    "        else:\n",
    "            ego_yaw_diff_init = ego_yaw_diff\n",
    "        ego_yaw_diff_window = ego_yaw_diff_init.reshape(1,-1) # (1, 49), row-major order flatten\n",
    "\n",
    "        ### final feature vector\n",
    "        feature = torch.cat([roted_ego_pos_diff_window, roted_ego_vel_diff_window, ego_yaw_diff_window], dim=1) # (1,245)\n",
    "        \n",
    "        # reverse transformation of prediction and targets\n",
    "        recovery_angle_mat = rot_mat\n",
    "        if not self.isTest:\n",
    "            recovery_pos_roted = roted_ego_pos[-61] # (2,)\n",
    "            label_pos = ego_pos[-60:] # (60,2)\n",
    "            return (\n",
    "                feature.float(), # (1,245)\n",
    "                recovery_pos_roted.float(), # (2)\n",
    "                recovery_angle_mat.float(), # (2,2)\n",
    "                label_pos.float(), # (60,2)\n",
    "                roted_ego_pos_diff_target.float(), # (60,2)\n",
    "                roted_ego_vel_diff_target.float(), # (60,2)\n",
    "                ego_yaw_diff_target.unsqueeze(1).float() # (60,1)\n",
    "            )\n",
    "        else: \n",
    "            recovery_pos_roted = roted_ego_pos[-1] # (2,)\n",
    "            return (\n",
    "                feature.float(), # (1,245)\n",
    "                recovery_pos_roted.float(), # (2)\n",
    "                recovery_angle_mat.float(), # (2,2)\n",
    "            )\n",
    "        \n",
    "feature_size = 2*49 + 2*49 + 49\n",
    "output_size = 2 + 2 + 1\n",
    "dataset = TrajectoryDataset(train_data, isTest=False)\n",
    "for tensor in dataset[1]: print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356bd412",
   "metadata": {
    "papermill": {
     "duration": 0.003084,
     "end_time": "2025-06-09T00:22:46.528895",
     "exception": false,
     "start_time": "2025-06-09T00:22:46.525811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create datasets and dataloaders, set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7889da92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:22:46.536037Z",
     "iopub.status.busy": "2025-06-09T00:22:46.535790Z",
     "iopub.status.idle": "2025-06-09T00:22:46.660515Z",
     "shell.execute_reply": "2025-06-09T00:22:46.659763Z"
    },
    "papermill": {
     "duration": 0.129783,
     "end_time": "2025-06-09T00:22:46.661760",
     "exception": false,
     "start_time": "2025-06-09T00:22:46.531977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "[torch.Size([128, 1, 245]), torch.Size([128, 2]), torch.Size([128, 2, 2]), torch.Size([128, 60, 2]), torch.Size([128, 60, 2]), torch.Size([128, 60, 2]), torch.Size([128, 60, 1])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 128\n",
    "train_dataset, val_dataset = random_split(dataset, [int(len(dataset)*0.9), int(len(dataset)*0.1)])\n",
    "train_dataset.train = True\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_val_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(len(train_loader))\n",
    "\n",
    "for batch in train_loader:\n",
    "    print([x.shape for x in batch])\n",
    "    break  # only the first batch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31f984f",
   "metadata": {
    "papermill": {
     "duration": 0.01116,
     "end_time": "2025-06-09T00:22:46.676436",
     "exception": false,
     "start_time": "2025-06-09T00:22:46.665276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b963813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:22:46.684269Z",
     "iopub.status.busy": "2025-06-09T00:22:46.683892Z",
     "iopub.status.idle": "2025-06-09T00:22:46.690993Z",
     "shell.execute_reply": "2025-06-09T00:22:46.690276Z"
    },
    "papermill": {
     "duration": 0.012251,
     "end_time": "2025-06-09T00:22:46.692117",
     "exception": false,
     "start_time": "2025-06-09T00:22:46.679866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class OneStepLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout):\n",
    "        \"\"\"\n",
    "        LSTM for one-step-ahead prediction\n",
    "        \n",
    "        Args:\n",
    "            input_size: number of input features (104)\n",
    "            hidden_size: number of LSTM hidden units\n",
    "            output_size: number of output features (2)\n",
    "            num_layers: number of LSTM layers\n",
    "        \"\"\"\n",
    "        super(OneStepLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.fc_in = nn.Linear(input_size, input_size)\n",
    "        self.ln_in = nn.LayerNorm(input_size)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc_out= nn.Linear(hidden_size, output_size)\n",
    "        self.init_h = nn.Parameter(torch.zeros(num_layers, hidden_size))\n",
    "        self.init_c = nn.Parameter(torch.zeros(num_layers, hidden_size))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        # x shape: (input_len, seq_length=110, input_size=104)\n",
    "        batch_size = x.size(0)\n",
    "        if h0==None:\n",
    "            h0 = self.init_h.unsqueeze(1).expand(-1, batch_size, -1).contiguous() # (num_layers, N, H_out)\n",
    "        if c0==None:\n",
    "            c0 = self.init_c.unsqueeze(1).expand(-1, batch_size, -1).contiguous() # (num_layers, N, H_out)\n",
    "\n",
    "        out = self.fc_in(x)\n",
    "        out = self.ln_in(out)\n",
    "        out = self.dropout(out)\n",
    "        out, (h_n, c_n) = self.lstm(out, (h0, c0)) # (N, L, H_out), (num_layers, N, H_out), (num_layers, N, H_out)\n",
    "        out = self.ln(out)\n",
    "        out = self.dropout(out)\n",
    "        predictions = self.fc_out(out) # # (N, L, 6)\n",
    "        \n",
    "        return predictions, h_n, c_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e9441",
   "metadata": {
    "papermill": {
     "duration": 0.003123,
     "end_time": "2025-06-09T00:22:46.698556",
     "exception": false,
     "start_time": "2025-06-09T00:22:46.695433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39580ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:22:46.706113Z",
     "iopub.status.busy": "2025-06-09T00:22:46.705446Z",
     "iopub.status.idle": "2025-06-09T00:22:46.714256Z",
     "shell.execute_reply": "2025-06-09T00:22:46.713750Z"
    },
    "papermill": {
     "duration": 0.01353,
     "end_time": "2025-06-09T00:22:46.715193",
     "exception": false,
     "start_time": "2025-06-09T00:22:46.701663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from copy import deepcopy\n",
    "\n",
    "def predict(model, inputs:tuple, criterion, isTest:bool):\n",
    "    if isTest:\n",
    "        feature, recovery_pos_roted, recovery_angle_mat = [x.to(device) for x in inputs]\n",
    "    else:\n",
    "        feature, recovery_pos_roted, recovery_angle_mat, label_pos, roted_pos_diff_target, roted_vel_diff_target, yaw_diff_target = [x.to(device) for x in inputs]\n",
    "    \n",
    "    roted_ego_pos_diff_window = feature[:,0,:98]\n",
    "    \n",
    "    roted_pos_diff_pred, roted_vel_diff_pred, yaw_diff_pred = [], [], []    \n",
    "    h = c = None\n",
    "    for t in range(60):\n",
    "        # The first 2 nums are roted_pos_diff_pred, second 2 nums are roted_vel_diff_pred, 5th num is yaw_diff_pred \n",
    "        output, h, c = model(feature, h, c) # (batch_size, 1, output_size)\n",
    "        rpd, rvd, yd = output[:,:,:2], output[:,:,2:4], output[:,:,[4]] # (batch_size, 1, 2), # (batch_size, 1, 2), # (batch_size, 1, 1)\n",
    "        roted_pos_diff_pred.append(rpd)\n",
    "        roted_vel_diff_pred.append(rvd)\n",
    "        yaw_diff_pred.append(yd)\n",
    "        feature = torch.cat([feature[:,:,2:98], rpd, feature[:,:,98+2:98+98], rvd, feature[:,:,98+98+1:], yd], dim=-1)  # 滚动窗口\n",
    "    \n",
    "    roted_pos_diff_pred = torch.cat(roted_pos_diff_pred, dim=1) # (batch_size, 60, 2)\n",
    "    if model.training==False:\n",
    "        for idx_in_batch, scene in enumerate(roted_ego_pos_diff_window):\n",
    "            first_movements_sum = torch.sum(torch.abs(scene))\n",
    "            if first_movements_sum < 1:\n",
    "                roted_pos_diff_pred[idx_in_batch] = torch.zeros((60, 2), device=device)\n",
    "    roted_vel_diff_pred = torch.cat(roted_vel_diff_pred, dim=1) # (batch_size, 60, 2)\n",
    "    yaw_diff_pred = torch.cat(yaw_diff_pred, dim=1) # (batch_size, 60, 2)\n",
    "\n",
    "    if not isTest:\n",
    "        loss_pos = criterion(roted_pos_diff_pred, roted_pos_diff_target)\n",
    "        loss_vel = criterion(roted_vel_diff_pred, roted_vel_diff_target)\n",
    "        loss_yaw = criterion(yaw_diff_pred, yaw_diff_target)\n",
    "    \n",
    "    ###### All teacher forcing\n",
    "    # batch_pred_pos_diff, _, _ = model(batch_X)  # shape: [64, 109, 6]\n",
    "    # batch_pred_pos = batch_pred_pos_diff + batch_recovery_pos\n",
    "    # loss = criterion(batch_pred_pos, batch_label_pos)\n",
    "    ######\n",
    "    \n",
    "    # compute original loss after reverse-transform\n",
    "    roted_pos_diff_pred[:,0,:] += recovery_pos_roted # (batch_size, 2)\n",
    "    roted_pos_pred = roted_pos_diff_pred.cumsum(dim=1) \n",
    "    pos_pred = roted_pos_pred @ recovery_angle_mat\n",
    "    if not isTest:\n",
    "        loss_pos_original = criterion(pos_pred, label_pos)\n",
    "\n",
    "    if not isTest:\n",
    "        return loss_pos, loss_vel, loss_yaw, loss_pos_original\n",
    "    else:\n",
    "        return pos_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e23faadc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:22:46.723565Z",
     "iopub.status.busy": "2025-06-09T00:22:46.722885Z",
     "iopub.status.idle": "2025-06-09T00:49:44.246275Z",
     "shell.execute_reply": "2025-06-09T00:49:44.245541Z"
    },
    "papermill": {
     "duration": 1617.528861,
     "end_time": "2025-06-09T00:49:44.247504",
     "exception": false,
     "start_time": "2025-06-09T00:22:46.718643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|██████████| 79/79 [00:17<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 1/100, LR: [0.001] | Train Loss: 1.0180, 82.3252 | Val Loss: 0.1920, 25.2260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 79/79 [00:16<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 2/100, LR: [0.001] | Train Loss: 0.3203, 21.6168 | Val Loss: 0.0880, 16.1135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 79/79 [00:16<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 3/100, LR: [0.001] | Train Loss: 0.2278, 17.5386 | Val Loss: 0.0632, 13.5971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 79/79 [00:16<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 4/100, LR: [0.001] | Train Loss: 0.1782, 15.2747 | Val Loss: 0.0601, 14.6139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 79/79 [00:16<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 5/100, LR: [0.001] | Train Loss: 0.1428, 13.4188 | Val Loss: 0.0523, 16.1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 79/79 [00:16<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 6/100, LR: [0.001] | Train Loss: 0.1241, 12.7242 | Val Loss: 0.0459, 11.5715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 79/79 [00:16<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 7/100, LR: [0.001] | Train Loss: 0.1074, 11.7187 | Val Loss: 0.0457, 14.5052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 79/79 [00:16<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 8/100, LR: [0.001] | Train Loss: 0.0959, 11.4163 | Val Loss: 0.0369, 11.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 79/79 [00:16<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 9/100, LR: [0.001] | Train Loss: 0.0892, 10.6928 | Val Loss: 0.0372, 10.6084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 79/79 [00:16<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 10/100, LR: [0.001] | Train Loss: 0.0810, 10.1582 | Val Loss: 0.0377, 10.8346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 79/79 [00:16<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 11/100, LR: [0.001] | Train Loss: 0.0745, 10.2034 | Val Loss: 0.0354, 10.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 79/79 [00:16<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 12/100, LR: [0.001] | Train Loss: 0.0689, 9.9663 | Val Loss: 0.0337, 10.5914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 79/79 [00:16<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 13/100, LR: [0.001] | Train Loss: 0.0660, 9.8664 | Val Loss: 0.0308, 9.9049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 79/79 [00:16<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 14/100, LR: [0.001] | Train Loss: 0.0607, 9.4754 | Val Loss: 0.0321, 10.6686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 79/79 [00:16<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 15/100, LR: [0.001] | Train Loss: 0.0587, 9.4796 | Val Loss: 0.0304, 9.3631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 79/79 [00:16<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 16/100, LR: [0.001] | Train Loss: 0.0538, 9.1589 | Val Loss: 0.0304, 10.5089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 79/79 [00:16<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 17/100, LR: [0.001] | Train Loss: 0.0530, 9.0142 | Val Loss: 0.0319, 11.0994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 79/79 [00:16<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 18/100, LR: [0.001] | Train Loss: 0.0511, 9.1077 | Val Loss: 0.0304, 9.8896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 79/79 [00:16<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 19/100, LR: [0.001] | Train Loss: 0.0504, 9.0794 | Val Loss: 0.0343, 9.6446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 79/79 [00:16<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 20/100, LR: [0.00015] | Train Loss: 0.0477, 8.8238 | Val Loss: 0.0281, 9.9744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 79/79 [00:16<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 21/100, LR: [0.00015] | Train Loss: 0.0436, 8.0522 | Val Loss: 0.0258, 8.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 79/79 [00:16<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 22/100, LR: [0.00015] | Train Loss: 0.0430, 7.7612 | Val Loss: 0.0256, 8.5418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 79/79 [00:16<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 23/100, LR: [0.00015] | Train Loss: 0.0426, 7.9432 | Val Loss: 0.0252, 8.5325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 79/79 [00:16<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 24/100, LR: [0.00015] | Train Loss: 0.0422, 7.7409 | Val Loss: 0.0244, 8.2765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 79/79 [00:16<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 25/100, LR: [0.00015] | Train Loss: 0.0414, 7.6575 | Val Loss: 0.0244, 8.3712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 79/79 [00:16<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 26/100, LR: [0.00015] | Train Loss: 0.0411, 7.7189 | Val Loss: 0.0249, 8.4169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 79/79 [00:16<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 27/100, LR: [0.00015] | Train Loss: 0.0407, 7.6612 | Val Loss: 0.0250, 8.5305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 79/79 [00:16<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 28/100, LR: [0.00015] | Train Loss: 0.0399, 7.6021 | Val Loss: 0.0239, 8.2465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 79/79 [00:16<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 29/100, LR: [0.00015] | Train Loss: 0.0402, 7.5999 | Val Loss: 0.0252, 8.5731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 79/79 [00:16<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 30/100, LR: [0.00015] | Train Loss: 0.0399, 7.8132 | Val Loss: 0.0247, 8.4515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 79/79 [00:16<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 31/100, LR: [0.00015] | Train Loss: 0.0393, 7.6345 | Val Loss: 0.0241, 8.3966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 79/79 [00:16<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 32/100, LR: [0.00015] | Train Loss: 0.0392, 7.6331 | Val Loss: 0.0238, 8.4135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 79/79 [00:16<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 33/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0386, 7.5719 | Val Loss: 0.0241, 8.2842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 79/79 [00:16<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 34/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0384, 7.3362 | Val Loss: 0.0232, 7.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 79/79 [00:16<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 35/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0381, 7.2888 | Val Loss: 0.0235, 8.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 79/79 [00:16<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 36/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0379, 7.3613 | Val Loss: 0.0234, 8.2319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 79/79 [00:16<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 37/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0376, 7.2422 | Val Loss: 0.0229, 7.9683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 79/79 [00:16<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 38/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0373, 7.2014 | Val Loss: 0.0234, 8.1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 79/79 [00:16<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 39/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0371, 7.1853 | Val Loss: 0.0234, 8.2235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 79/79 [00:16<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 40/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0376, 7.2736 | Val Loss: 0.0229, 7.8968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 79/79 [00:16<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 41/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0375, 7.2682 | Val Loss: 0.0230, 7.9418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 79/79 [00:16<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 42/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0371, 7.2459 | Val Loss: 0.0229, 7.9329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 79/79 [00:16<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 43/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0372, 7.3358 | Val Loss: 0.0229, 8.0908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 79/79 [00:16<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 44/100, LR: [2.2499999999999998e-05] | Train Loss: 0.0370, 7.2676 | Val Loss: 0.0229, 8.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 79/79 [00:16<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 45/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0367, 7.2027 | Val Loss: 0.0228, 7.9066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 79/79 [00:16<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 46/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0366, 7.2004 | Val Loss: 0.0228, 7.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 79/79 [00:16<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 47/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0365, 7.1266 | Val Loss: 0.0229, 7.8969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 79/79 [00:16<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 48/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0367, 7.2281 | Val Loss: 0.0228, 7.8940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 79/79 [00:16<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 49/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0367, 7.1314 | Val Loss: 0.0228, 7.8715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 79/79 [00:16<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 50/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0367, 7.1754 | Val Loss: 0.0229, 7.9865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 79/79 [00:16<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 51/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0367, 7.1299 | Val Loss: 0.0229, 7.9022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 79/79 [00:16<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 52/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0368, 7.1447 | Val Loss: 0.0228, 7.8514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 79/79 [00:16<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 53/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0368, 7.1689 | Val Loss: 0.0228, 7.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 79/79 [00:16<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 54/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0367, 7.1614 | Val Loss: 0.0230, 7.9341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 79/79 [00:16<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 55/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0367, 7.1213 | Val Loss: 0.0227, 7.8374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 79/79 [00:16<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 56/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0368, 7.1753 | Val Loss: 0.0228, 7.8902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 79/79 [00:16<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 57/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0366, 7.1077 | Val Loss: 0.0228, 7.8452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 79/79 [00:17<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 58/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0366, 7.1437 | Val Loss: 0.0226, 7.8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 79/79 [00:17<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 59/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0366, 7.1193 | Val Loss: 0.0228, 7.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 79/79 [00:17<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 60/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0367, 7.2052 | Val Loss: 0.0228, 7.9666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 79/79 [00:17<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 61/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0366, 7.1515 | Val Loss: 0.0228, 7.9533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 79/79 [00:17<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 62/100, LR: [3.3749999999999995e-06] | Train Loss: 0.0365, 7.1265 | Val Loss: 0.0227, 7.8259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 79/79 [00:17<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 63/100, LR: [5.062499999999999e-07] | Train Loss: 0.0366, 7.1554 | Val Loss: 0.0228, 7.9061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 79/79 [00:17<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 64/100, LR: [5.062499999999999e-07] | Train Loss: 0.0363, 7.0394 | Val Loss: 0.0228, 7.8829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 79/79 [00:17<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 65/100, LR: [5.062499999999999e-07] | Train Loss: 0.0366, 7.2249 | Val Loss: 0.0227, 7.8699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 79/79 [00:17<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 66/100, LR: [5.062499999999999e-07] | Train Loss: 0.0365, 7.1494 | Val Loss: 0.0226, 7.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 79/79 [00:17<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 67/100, LR: [5.062499999999999e-07] | Train Loss: 0.0365, 7.1229 | Val Loss: 0.0228, 7.8954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 79/79 [00:17<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 10000 samples for training, so this isn't really hold-out validation set\n",
      "Epoch 68/100, LR: [7.593749999999999e-08] | Train Loss: 0.0364, 7.0449 | Val Loss: 0.0226, 7.8400\n",
      "training finished, best val loss = 7.808046318307707\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss(reduction='mean')  # For regression task\n",
    "def train_model(model, train_loader, val_loader, epochs, optimizer, scheduler):\n",
    " \n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "\n",
    "    model.to(device)\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "    patience = 10\n",
    "    isTest = False\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_loss_original = 0.0\n",
    "        train_loader = train_val_loader    \n",
    "        if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") == \"Batch\":\n",
    "            train_loader = train_val_loader\n",
    "        for inputs in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
    "            optimizer.zero_grad()\n",
    "            loss_pos, loss_vel, loss_yaw, loss_pos_original = predict(model, inputs, criterion, isTest)\n",
    "            (loss_pos_original+loss_vel+loss_yaw).backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss_pos.item() # MSE doesn't average but sums when the reduction is 'sum'\n",
    "            train_loss_original += loss_pos_original.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_loss_original /= len(train_loader)\n",
    "        train_loss_list.append(train_loss_original)\n",
    "        \n",
    "        # Validation phase (50-109 autoregressive)\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_loss_original = 0.0\n",
    "        if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") == \"Batch\":\n",
    "            print(\"Using all 10000 samples for training, so this isn't really hold-out validation set\")\n",
    "            val_loader = train_val_loader\n",
    "        with torch.no_grad():\n",
    "            for inputs in val_loader:\n",
    "                loss_pos, loss_vel, loss_yaw, loss_pos_original = predict(model, inputs, criterion, isTest)\n",
    "                val_loss += loss_pos.item()\n",
    "                val_loss_original += loss_pos_original.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_loss_original /= len(val_loader)\n",
    "        val_loss_list.append(val_loss_original)\n",
    "        scheduler.step(val_loss_original)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, LR: {scheduler.get_last_lr()} | Train Loss: {train_loss:.4f}, {train_loss_original:.4f} | Val Loss: {val_loss:.4f}, {val_loss_original:.4f}')\n",
    "\n",
    "        if val_loss_original < best_loss:\n",
    "            best_loss = val_loss_original\n",
    "            best_model = deepcopy(model)\n",
    "            patience = 10\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience <= 0:\n",
    "                break\n",
    "    \n",
    "    return best_loss, best_model, train_loss_list, val_loss_list\n",
    "    \n",
    "model = OneStepLSTM(input_size=feature_size, hidden_size=256, output_size=output_size, num_layers=2, dropout=0.2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.15, patience=4, verbose=True)\n",
    "best_loss, model, train_loss_list, val_loss_list = train_model(model=model, train_loader=train_loader, val_loader=val_loader, epochs=100, optimizer=optimizer, scheduler=scheduler)\n",
    "print('training finished, best val loss =', best_loss)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(train_loss_list, label=\"Train Loss (World Frame)\")\n",
    "plt.plot(val_loss_list, label=\"Val Loss (World Frame)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Training & Validation Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf5fa106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:49:44.726849Z",
     "iopub.status.busy": "2025-06-09T00:49:44.726458Z",
     "iopub.status.idle": "2025-06-09T00:49:44.729943Z",
     "shell.execute_reply": "2025-06-09T00:49:44.729331Z"
    },
    "papermill": {
     "duration": 0.228565,
     "end_time": "2025-06-09T00:49:44.730974",
     "exception": false,
     "start_time": "2025-06-09T00:49:44.502409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raise ValueError(\"Stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d03a9",
   "metadata": {
    "papermill": {
     "duration": 0.221496,
     "end_time": "2025-06-09T00:49:45.176989",
     "exception": false,
     "start_time": "2025-06-09T00:49:44.955493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate predictions for a few scenes and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d4bb029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:49:45.684983Z",
     "iopub.status.busy": "2025-06-09T00:49:45.684700Z",
     "iopub.status.idle": "2025-06-09T00:49:45.709036Z",
     "shell.execute_reply": "2025-06-09T00:49:45.708237Z"
    },
    "papermill": {
     "duration": 0.311032,
     "end_time": "2025-06-09T00:49:45.710296",
     "exception": false,
     "start_time": "2025-06-09T00:49:45.399264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# make gif out of a scene.\n",
    "def make_gif(data_matrix, data_matrix_2, name, isTest):\n",
    "   cmap = plt.cm.get_cmap('viridis', 50)\n",
    "   fig, ax = plt.subplots(figsize=(10, 10))\n",
    "   # Function to update plot for each frame\n",
    "   def update(frame):\n",
    "       ax.clear()\n",
    "       if frame<50 or isTest==False:\n",
    "           ax.plot(data_matrix[:frame, 0], data_matrix[:frame, 1], color='tab:orange', label='Ego Vehicle')\n",
    "           ax.scatter(data_matrix[frame, 0], data_matrix[frame, 1], s=80, color='tab:orange')\n",
    "       if frame>=50:\n",
    "           frame_2 = frame-50\n",
    "           ax.plot(data_matrix_2[:frame_2, 0], data_matrix_2[:frame_2, 1], color='tab:blue', label='Predicted Ego Vehicle')\n",
    "           ax.scatter(data_matrix_2[frame_2, 0], data_matrix_2[frame_2, 1], s=80, color='tab:blue')\n",
    "       # Set title with timestep\n",
    "       ax.set_title(f\"{'Test data,' if isTest else 'Train data,'}, Scene {name} Timestep {frame}\")\n",
    "       # Set consistent axis limits\n",
    "       ax.set_xlim(min(data_matrix[:,0].min(),data_matrix_2[:,0].min()) - 10, max(data_matrix[:,0].max(), data_matrix_2[:,0].max()) + 10)\n",
    "       ax.set_ylim(min(data_matrix[:,1].min(),data_matrix_2[:,1].min()) - 10, max(data_matrix[:,1].max(), data_matrix_2[:,1].max()) + 10)\n",
    "       ax.legend()\n",
    "\n",
    "       return ax.collections + ax.lines\n",
    "\n",
    "   # Create animation\n",
    "   anim = animation.FuncAnimation(fig, update, frames=list(range(0, 109, 3)),\n",
    "                               interval=100, blit=True)\n",
    "   # Save as GIF\n",
    "   anim.save(f\"trajectory_visualization_{'Test data,' if isTest else 'Train data,'}_{scene_idx}.gif\", writer='pillow')\n",
    "   plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26d90cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:49:46.159285Z",
     "iopub.status.busy": "2025-06-09T00:49:46.159007Z",
     "iopub.status.idle": "2025-06-09T00:49:46.165932Z",
     "shell.execute_reply": "2025-06-09T00:49:46.165399Z"
    },
    "papermill": {
     "duration": 0.233951,
     "end_time": "2025-06-09T00:49:46.167135",
     "exception": false,
     "start_time": "2025-06-09T00:49:45.933184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") != \"Batch\":\n",
    "    dataset = TrajectoryDatasetTrain(train_data)\n",
    "    for scene_idx in range(20):\n",
    "        roted_ego_poses_diff_window, recovery_pose_roted, recovery_angle_mat, label_poses, _ = dataset[scene_idx] # (1,98), (2,), (2,2)\n",
    "        full_traj = train_data[scene_idx,0,:,:2]\n",
    "        \n",
    "        roted_ego_poses_diff_window = roted_ego_poses_diff_window.to(device).unsqueeze(0) # add batch dimension since batch_first=True\n",
    "        recovery_pose_roted, recovery_angle_mat = recovery_pose_roted.to(device), recovery_angle_mat.to(device) # (batch_size, 2), # (batch_size, 60, 2)\n",
    "\n",
    "        last_movements_sum = torch.sum(torch.abs(roted_ego_poses_diff_window[0,0,-2*5:]))\n",
    "        last_avg_acceleration = (roted_ego_poses_diff_window[0,0,-1] - roted_ego_poses_diff_window[0,0,-2*5]) / 9\n",
    "        print(f'last_movements_sum for scene {scene_idx}: {last_movements_sum} ')\n",
    "        print(f'last_avg_acceleration for scene {scene_idx}: {last_avg_acceleration} ')\n",
    "        \n",
    "        if last_movements_sum < 1.2:\n",
    "            roted_pos_diff_pred = torch.zeros((roted_ego_poses_diff_window.shape[0], 60, 2), device=device)\n",
    "        else:\n",
    "            roted_pos_diff_pred = []    \n",
    "            h = c = None\n",
    "            for t in range(60):\n",
    "                output, h, c = model(roted_ego_poses_diff_window, h, c)\n",
    "                roted_pos_diff_pred.append(output) # (batch_size, 1, 2)\n",
    "                roted_ego_poses_diff_window = torch.cat([roted_ego_poses_diff_window[:,:,2:], output], dim=-1)  # 滚动窗口\n",
    "            roted_pos_diff_pred = torch.cat(roted_pos_diff_pred, dim=1) # (batch_size, 60, 2)\n",
    "        \n",
    "        roted_pos_diff_pred[:,0,:] += recovery_pose_roted # (batch_size, 2)\n",
    "        roted_pos_pred = roted_pos_diff_pred.cumsum(dim=1) \n",
    "        traj_pred = roted_pos_pred.squeeze(0) @ recovery_angle_mat\n",
    "        # print(traj_pred)\n",
    "        # print(full_traj)\n",
    "        make_gif(full_traj, traj_pred.cpu().detach().numpy(), name=f'index {scene_idx}', isTest=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9bc223",
   "metadata": {
    "papermill": {
     "duration": 0.22076,
     "end_time": "2025-06-09T00:49:46.610747",
     "exception": false,
     "start_time": "2025-06-09T00:49:46.389987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test and write to submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16265e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:49:47.112249Z",
     "iopub.status.busy": "2025-06-09T00:49:47.111989Z",
     "iopub.status.idle": "2025-06-09T00:49:47.118955Z",
     "shell.execute_reply": "2025-06-09T00:49:47.118400Z"
    },
    "papermill": {
     "duration": 0.231312,
     "end_time": "2025-06-09T00:49:47.120090",
     "exception": false,
     "start_time": "2025-06-09T00:49:46.888778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") != \"Batch\":\n",
    "    dataset = TrajectoryDatasetTest(test_data)\n",
    "    for scene_idx in range(20):\n",
    "        roted_ego_poses_diff_window, recovery_pose_roted, recovery_angle_mat = dataset[scene_idx] # (1,98), (2,), (2,2)\n",
    "        full_traj = test_data[scene_idx,0,:,:2]\n",
    "        \n",
    "        roted_ego_poses_diff_window = roted_ego_poses_diff_window.to(device).unsqueeze(0) # add batch dimension since batch_first=True\n",
    "        recovery_pose_roted, recovery_angle_mat = recovery_pose_roted.to(device), recovery_angle_mat.to(device) # (batch_size, 2), # (batch_size, 60, 2)\n",
    "\n",
    "        last_movements_sum = torch.sum(torch.abs(roted_ego_poses_diff_window[0,0,-2*5:]))\n",
    "        last_avg_acceleration = (roted_ego_poses_diff_window[0,0,-1] - roted_ego_poses_diff_window[0,0,-2*5]) / 9\n",
    "        print(f'last_movements_sum for scene {scene_idx}: {last_movements_sum} ')\n",
    "        print(f'last_avg_acceleration for scene {scene_idx}: {last_avg_acceleration} ')\n",
    "        \n",
    "        if last_movements_sum < 1.2:\n",
    "            roted_pos_diff_pred = torch.zeros((roted_ego_poses_diff_window.shape[0], 60, 2), device=device)\n",
    "        else:\n",
    "            roted_pos_diff_pred = []    \n",
    "            h = c = None\n",
    "            for t in range(60):\n",
    "                output, h, c = model(roted_ego_poses_diff_window, h, c)\n",
    "                roted_pos_diff_pred.append(output) # (batch_size, 1, 2)\n",
    "                roted_ego_poses_diff_window = torch.cat([roted_ego_poses_diff_window[:,:,2:], output], dim=-1)  # 滚动窗口\n",
    "            roted_pos_diff_pred = torch.cat(roted_pos_diff_pred, dim=1) # (batch_size, 60, 2)\n",
    "            \n",
    "        roted_pos_diff_pred[:,0,:] += recovery_pose_roted # (batch_size, 2)\n",
    "        roted_pos_pred = roted_pos_diff_pred.cumsum(dim=1) \n",
    "        traj_pred = roted_pos_pred.squeeze(0) @ recovery_angle_mat\n",
    "        # print(traj_pred)\n",
    "        # print(full_traj)\n",
    "        make_gif(full_traj, traj_pred.cpu().detach().numpy(), name=f'test scene {scene_idx}', isTest=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce4c3590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:49:47.562812Z",
     "iopub.status.busy": "2025-06-09T00:49:47.562212Z",
     "iopub.status.idle": "2025-06-09T00:49:49.860531Z",
     "shell.execute_reply": "2025-06-09T00:49:49.859849Z"
    },
    "papermill": {
     "duration": 2.52106,
     "end_time": "2025-06-09T00:49:49.862029",
     "exception": false,
     "start_time": "2025-06-09T00:49:47.340969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 245])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:1124: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1412.)\n",
      "  result = _VF.lstm(\n"
     ]
    }
   ],
   "source": [
    "isTest = True\n",
    "dataset = TrajectoryDataset(test_data, isTest=isTest)\n",
    "for tensor in dataset[1]: print(tensor.shape)\n",
    "test_loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_scene_preds = []\n",
    "    for inputs in test_loader:\n",
    "        pos_pred = predict(model, inputs, criterion, isTest)\n",
    "        all_scene_preds.append(pos_pred)\n",
    "        \n",
    "all_scene_preds = torch.cat(all_scene_preds,dim=0).reshape(-1,2)\n",
    "import pandas as pd\n",
    "output_df = pd.DataFrame(all_scene_preds.cpu().numpy(), columns=['x', 'y'])\n",
    "output_df.index.name = 'index'\n",
    "output_df.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11656558,
     "sourceId": 97693,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1655.269591,
   "end_time": "2025-06-09T00:49:53.581960",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-09T00:22:18.312369",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
